%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2022}{Austin, TX}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{What's in a Domain? Anaylsis of URL Features}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{John Hawkins}
\email{john.hawkins@Getting-Data-Science-Done.com}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Getting-Data-Science-Done.com}
  \city{Sydney}
  \state{NSW}
  \country{Australia}
  \postcode{2000}
}

\renewcommand{\shortauthors}{Hawkins}

\begin{abstract}
Many data science problems require processing log data derived from web pages, apis or other
internet traffice sources. URLs are one of the few universal pieces of information that describe
internet activity, hence URLs require effective processing for a wide variety of machine 
learning applications. While URLs are structurally rich, they are not subject
to universal principles of construction making fetaure engineering for internet data an ongoing challenge.

In this research we outline the key categories of information structure in domains and URLs.
We share an open source implementation of these ideas and demonstrate their utility across a range of 
internet traffic machine learning problems.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003260.10003261</concept_id>
<concept_desc>Information systems~Web searching and information discovery</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002951.10003260.10003277.10003280</concept_id>
<concept_desc>Information systems~Web log analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Web searching and information discovery}
\ccsdesc[500]{Information systems~Web log analysis}
\ccsdesc[500]{Computing methodologies~Machine learning}

\keywords{URL Features, Document Classification, Machine Learning, Semantic Web}

\maketitle

\section{Introduction}

The Uniform Resource Locator (URL) is now a ubiquitous element of modern life. 
We use them to advertise and locate businesses, to retrieve news and media and 
to interact with other people across a broad of social applications. It should
be no surprise that processing URLs is key component of many tasks that involve
analysing internet data. In many applications the URL is the central piece of 
information available because the demands of the task require immediate analysis.
Prominent examples include security analysis of potenital phishing attacks\cite{Basnet2014}, 
detection of potential spam emails \cite{}, and applications to online advertsing
including anticipation of conversions \cite{Qiu2020} or contextual analysis of
the content\cite{Kan2005,Baykan2009} or language\cite{Baykan2013} of webpages. 

The URL is made up of multiple elements, but at its core is the domain. The domain
contains internal information about both its intended purpose, legitimacy and likely
origin. It is also a source of additional information through requests to Domain Name
Servers (DNS) to understand both its history and place within the network topology.

Common feature engineering strategies exploit these potential sources of information
in ways that are appropriate for a given task. However, while there are wide variety
of approaches that inconsistently applied, there has not yet been a study that evaluates
the overall effectiveness of different strategies across a range of applications.

In this work we describe an ontology of URL fetaures that relates to underlying origin
and purpose. We then present an open source package for generating features within these
ontologocal classes and apply them to a variety of tasks. We present our results as a
cross-task evaluation of URL features.  

Multiple data science and machine learning applications on internet data 
Write a literature review \cite{Vazhayil2018}
\cite{Canali2011}
\cite{Ayes2019}
\cite{Mamun2016}
\cite{Li2020}
\cite{Basnet2012}
\cite{Basnet2014}
\cite{Tupsamudre2019}
\cite{Le2018}
\cite{Baykan2009}
\cite{Kan2005}
\cite{Hernandez2012}
\cite{Chung2010}
\cite{Qiu2020}
\cite{Vaishnavi2021}
\cite{Xu2021}
\cite{Rhea2022}
\cite{Ma2009}
\cite{Verma2017}
\cite{Sountharrajan2020}

Common approaches to feature engineering on URLs include string patterns and regular expressions to
identify key sequences \cite{}, n-gram models \cite{Baykan2009}, 
the generation of task specific embedding vectors\cite{Qiu2020} and the
usage of domain name servers or registrars for ancillary information \cite{}


\section{Methodology}


\begin{table}
  \caption{Attention Measurement Model - Aggregate Error}
  \label{tab:atm}
\begin{tabular}{|l|r|r|}
\toprule
Metric                  &Banner       &MREC       \\
\midrule
Aggregate MAE           &10.5 ms      &12.5 ms    \\
95\% Upper Bound        &19.0 ms      &20.6 ms    \\
95\% Lower Bound        &-22.8 ms     &-31.1 ms   \\
  \bottomrule
\end{tabular}
\end{table}

The signals collected along with the eye tracking data allow us to build and deploy an
attention measurment model that can predict the attention time paid to
specific ad units within a page. The attention model can
be applied to all digital inventory that accepts the javascript tag.

Our model evaluation process focuses on the accuracy of measuring mean
attention time for a specific ad format, over varying samples of inventory.
To generate the performance statistics we run bootstrap sampling of the test data
to look at the expected error when predicting the mean attention time over
impressions for a specific ad format. Each metric is calculated by taking 50 impression
samples 2000 times, and using the resulting distribution of mean error.
The mean attention time measurement performance is summarised in Table
\ref{tab:atm}.
We see that the aggregate mean absolute error (MAE) for both formats is very low
at $10.5 ms$ and $12.5 ms$ for banners and MRECs respectively. Furthermore, the
$95\%$ confidence intervals for these values is tightly constrained to be well under
$50 ms$ either side of the true value.
We apply this attention measurement model across large scale digitial inventory to
collect a data set of attention time paid to a range of advertisments over time.
We use these attention measured impressions to investigate the
impact of contextual categories of media on the attention paid to advertising.

\subsection{Data}

The data used in this study was collected from a collction of publications that 
present internet classification problems containing URLs as a key, or sole feature.
Malcious URL classification \cite{Mamun2016}.


4 Universities data http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/


\begin{table}
\caption{Datasets}
\label{tab:dataset}
\begin{tabular}{|l|r|r|}
\toprule
Metric          &Feb 18 - 24    &Feb 25 - March 03          \\
\midrule
Impressions     &16,895,661     &10,488,816     \\
URLS            &26,006         &27,855         \\
Domains         &2,263          &2,585          \\
Creatives       &683            &683            \\
Advertisers     &59             &59             \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Contextual Categorisation}

Verity had returned the
highest score and converted that category into a set of labels for
classification across the four Tiers of iAB V2.0. In instances where the
classified category is from a higher position in the hierarchy, then the
lower level tiers are given the deepest category. For example, if we have
a URL that is classified as iABv2 category "Business and Finance"
(a Tier 1 category) then Tiers 2, 3 and 4 will also contain the same value.

Alternatively, if we have another URL that is classified as "Marketing and Advertising"
(a Tier3 category below "Business and Finance"), then the hierarchical labels
would be assigned as follows:

\begin{itemize}
    \item {\texttt{Tier 1}}: ["Business and Finance"]
    \item {\texttt{Tier 2}}: ["Business"]
    \item {\texttt{Tier 3}}: ["Marketing and Advertising"]
    \item {\texttt{Tier 4}}: ["Marketing and Advertising"]
\end{itemize}


The idea of this scheme is that every page will be assigned a categorisation across
all four levels in the hierarchy, but sometimes the category at a given Tier
will not be any more specific than the parent category. This approach ensures
that comparisons can always be made, and when we look at a deeper level in the hierarchy
we will have at least as many distinct categories as the parent.

\subsection{Metrics}

The focus of our analysis is to determine whether the performance of each creative,
in a set of contexts, remains consistent across the two time periods.
Within each time period we aggregate
the measured attention time over the impression level data to obtain multiple metrics
for the reliability of attention time within a given context.


The attention metrics are calculated for a set of impressions $I_p$ in a time period $p$.
We first define a baseline for a creative $c$ in period $p$ as:
${}^c\mathcal{A}_p$. This is defined in equation \ref{campaign_baseline}.

\begin{equation}
\label{campaign_baseline}
{}^c\mathcal{A}_p =  \frac{ \sum_{i \in I_p} \mathbf{1}^c(i) A_i }{ \sum_{i \in I_p} \mathbf{1}^c(i) }
\end{equation}

Where the function $A(i)$ returns the attention measured on impression $i$ and
$\mathbf{1}^c(i)$ is an indicator function that
tests whether impression $i$ belongs to creative $c$, as shown in equation \ref{indicator}.

\begin{equation}
\label{indicator}
  \mathbf{1}^{c}(i):=
  \begin{cases}1~&{\text{ if }}~i\in c~,\\0~&{\text{ if }}~i\notin c~.\end{cases}
\end{equation}

Similarly, we denote the baseline attention achieved by ads on pages classified
as belonging to category $t$ in period $p$ as: ${}_t\mathcal{A}_p$. Defined in
equation \ref{topic_baseline}. Note, we use the notation $t$ for categories as they
are equivalent to topics, and this distinguishes them from the creatives.


\begin{equation}
\label{topic_baseline}
{}_t\mathcal{A}_p =  \frac{ \sum_{i \in I_p} \mathbf{1}_t(i) A(i) }{ \sum_{i \in I_p} \mathbf{1}_t(i) }
\end{equation}

Where $\mathbf{1}_t(i)$ is an indicator function that
tests whether impression $i$ was shown on a page classified as category $t$,
as show in in equation \ref{indicator2}.

\begin{equation}
\label{indicator2}
  \mathbf{1}_{t}(i):=
  \begin{cases}1~&{ i\text{ categorised as }}~t~,\\0~&{\text{ otherwise }}.\end{cases}
\end{equation}

We denote the mean attention performance for a creative $c$, on media of category $t$
within period $p$ as ${}^c_t\mathcal{A}_p$.
This is defined as shown in Equation \ref{mean_attention}.

\begin{equation}
\label{mean_attention}
{}^c_t\mathcal{A}_p =  \frac{ \sum_{i \in I_p} \mathbf{1}^c_t(i) A(i) }{ \sum_{i \in I_p} \mathbf{1}^c_t(i) }
\end{equation}

Where we simply apply a indicator function $\mathbf{1}^c_t(i)$ that is a composite
of Equations \ref{indicator} and \ref{indicator2} to filter for inventory that
belongs both to creative $c$ and category $t$. These equations should illustrate that we
make our evaluations by looking at the expected attention time across difference slices
of the inventory.

\subsection{Analysis}

Our analysis proceeds by ranking all topics that each creative $c$ was exposed
to according to the value of ${}^c_t\mathcal{A}_1$.
We then look at the same creatives in period 2 and
evaluate ${}^c_t\mathcal{A}_2$ for the top three ranking categories from the first period,
as well as the bottom ranking category.
This approach necessitates that each creative be exposed to a minimum
of these same 4 categories in both periods.
In the results that will follow we report the number
of records in each trial, reflecting the number of aggregated records
that fulfills these requirements.

Once we have the datasets in each period that meet these requirements we use multiple metrics
to evaluate the impact of the contextual categories. Our primary metric is the percentage
of instances in which the category specific performance ${}^c_t\mathcal{A}_2$ is above the
creative's baseline expected performance ${}^c\mathcal{A}_1$.
This is shown as \textbf{\% Over} (the baseline) in the tables of results.

In addition we look at the mean difference between ${}^c_t\mathcal{A}_2$ and ${}^c\mathcal{A}_1$
over all creatives in the experiment. This is denoted \boldmath$\mu\delta$ (or mean delta) in
the tables and defined in Equation \ref{delta}

\begin{equation}
\label{delta}
\mu\delta = \frac{ \sum_{c \in \mathcal{C}} {}^c_t\mathcal{A}_2 - {}^c\mathcal{A}_1 }{ \mathcal{C} }
\end{equation}

The mean delta illustrates an expectation of the difference between attention time performance
and the creative baseline, using a specific contextual targeting strategy. In addition, we show
that difference expressed as a mean percentage (against the baseline) in the column
$\mathbf{\mu\%\delta}$. This can be interpreted as the expected percentage increase/decrease
relative to the creative's baseline attention, when using that contextual targeting strategy.


\section{Results}

We conduct two variations of the experiment, each one looking at different
criteria for evaluating performance on new inventory.
These are referred to as the
\emph{No URL Repeats} and the \emph{No Domain Repeats} experiments.

\subsection{No URL Repeats}

In Table \ref{tab:nourlrepeats} we see the results of looking at performance on novel
URLs for a creative, where the iAB V2.0 contextual categories of those URLs were present
in either the top three or last ranking position in the initial period.

\begin{table}
\caption{Attention Performance by Category Rank on Novel URLs}
\label{tab:nourlrepeats}
\begin{tabular}{|l|r|l|r|r|r|}
\toprule
Level   &Count    &Rank &\% Over  &$\mu\delta$  &$\mu\%\delta$        \\
\midrule
Tier1   &206      &1st  &100.0\%    &4.5         &93.2\%     \\
        &         &2nd  &96.6\%     &2.6         &49.8\%     \\
        &         &3rd  &80.6\%     &1.4         &28.7\%     \\
        &         &Last &0.0\%      &-3.7        &-53.3\%     \\
Tier2   &210      &1st  &99.5\%     &6.3         &132.0\%     \\
        &         &2nd  &95.7\%     &3.7         &68.6\%     \\
        &         &3rd  &80.0\%     &2.4         &41.2\%     \\
        &         &Last &0.0\%      &-4.1        &-59.2\%     \\
Tier3   &210      &1st  &99.5\%     &6.4         &135.7\%     \\
        &         &2nd  &95.7\%     &3.8         &69.5\%     \\
        &         &3rd  &79.5\%     &2.4         &41.8\%     \\
        &         &Last &0.0\%      &-4.1        &-59.2\%     \\
Tier4   &210      &1st  &99.5\%     &6.4         &135.7\%     \\
        &         &2nd  &95.7\%     &3.8         &69.5\%     \\
        &         &3rd  &79.5\%     &2.4         &41.8\%     \\
        &         &Last &0.0\%      &-4.1        &-59.2\%     \\
\bottomrule
\end{tabular}
\end{table}

We see that, in general, targeting pages using categories deeper into the hierarchy
improves the expected increase in attention through contextual targeting.
However, the effect appears to plateau at Tier3, likely due to the small proportion of inventory
that is uniquely classified at a Tier 4 level.

\subsection{No Domain Repeats}
We repeat the analysis restricting ourselves to impressions in the second period
that involve URLS for which the domain was not present in the URLs for the first period.
The results are shown in Table \ref{tab:nodomainrepeats}.
We note that the number of records has dropped by
more than half in this experiment, due to the difficulty of finding domains that were
not present in the first period.

\begin{table}
\caption{Attention Performance by Category Rank on Novel Domains}
\label{tab:nodomainrepeats}
\begin{tabular}{|l|r|l|r|r|r|}
\toprule
Level   &Count  &Rank &\% Over  &$\mu\delta$  &$\mu\%\delta$        \\
\midrule
Tier1   &86       &1st  &98.8\%     &5.2         &144.3\%     \\
        &         &2nd  &83.7\%     &2.3         &58.8\%     \\
        &         &3rd  &60.5\%     &0.4         &26.9\%     \\
        &         &Last &0.0\%      &-4.1        &-64.5\%     \\
Tier2   &83       &1st  &96.4\%     &6.4         &159.1\%     \\
        &         &2nd  &84.3\%     &2.6         &71.0\%     \\
        &         &3rd  &59.0\%     &0.7         &35.8\%     \\
        &         &Last &0.0\%      &-4.5        &-70.0\%     \\
Tier3   &82       &1st  &96.3\%     &6.5         &161.3\%     \\
        &         &2nd  &84.2\%     &2.7         &71.2\%     \\
        &         &3rd  &56.1\%     &0.6         &34.7\%     \\
        &         &Last &0.0\%      &-4.6        &-69.9\%     \\
Tier4   &82       &1st  &96.3\%     &6.5         &161.3\%     \\
        &         &2nd  &84.2\%     &2.7         &71.6\%     \\
        &         &3rd  &56.1\%     &0.6         &34.7\%     \\
        &         &Last &0.0\%      &-4.6        &-69.9\%     \\
\bottomrule
\end{tabular}
\end{table}


The restriction to unique domains in the second period has lifted the expected improvement
of targeting the top performing category (Tier 3) from 135% to 161%. However, this improvement
only occurs with the category in ranking position one. For the other ranking positions
the results are mixed, even though the percentage amount is sometimes higher, the
absolute amount can be lower, due to the fact that the baseline is calculated on
the impressions that qualify for inclusion.

These result seems counterintuitive at first glance. Our current hypothesis about why
this is the case is that it relates to the specificity of the content on a given domain.
The \emph{no domain repeats} study is biased towards data on less common domains.
These may have a tendency to be more subject specific.
These ideas need to be tested in follow up research.

Additionally, we note that the percentage of instances where the category targeting
delivers an improvement over the baseline drops when we look at unique domains.
This drop is approximately 3% for rank 1 categories, but by the time we arrive at
the 3rd ranked category it has dropped from 80% to 56% at Tier 4, meaning that
targeting new domains with the 3rd ranked category offers a marginally better than
random chance of delivering improved attention.


\section{Conclusion}

\section{Acknowledgments}

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
